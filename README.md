
# **ConscienceAI**  
### *Auditing AI for Fairness, Explainability, and Ethical Compliance*

![Ethics Gauge](https://img.shields.io/badge/Ethics-Audited-blue) ![License](https://img.shields.io/badge/License-MIT-green)

---

## **ðŸ“– Overview**

**ConscienceAI** is an end-to-end machine learning pipeline that goes beyond accuracy. It assesses **AI models for ethics, fairness, and transparency**, ensuring responsible AI development

This project automates:
- **Bias Detection & Fairness Auditing**
- **Explainability using SHAP**
- **Ethics Score Calculation**
- **Policy Compliance Checklist**
- **Interactive Gauge Visualization**

---

## **ðŸ§° Features**

| Feature | Description |
|----------|-------------|
| **Model Training** | Logistic Regression (on income prediction dataset) |
| **Explainability** | SHAP Summary Plot for feature importance |
| **Fairness Audit** | Demographic Parity & Equalized Odds analysis |
| **Ethics Scorecard** | Combines Bias, Explainability & Data Quality into a score |
| **Policy Checklist** | Ensures AI policy guidelines are followed |
| **Visualization** | Interactive Ethics Gauge via Plotly |

---

## **ðŸ“¦ Installation**

Run the following to install dependencies:

```bash
pip install pandas numpy scikit-learn shap fairlearn matplotlib seaborn plotly
```

---

## **ðŸ“‚ Dataset**

- Uses **Adult Income Dataset (UCI)** or any similar dataset with:
  - **Features:** Age, Race, Gender, Occupation, etc.
  - **Target:** Income classification (`>50K` or `<=50K`)

Upload the dataset using:

```python
from google.colab import files
uploaded = files.upload()
```

---

## **âš™ï¸ How It Works**

1. **Preprocessing**
   - Handle nulls & encode categorical data
2. **Model Training**
   - Logistic Regression for binary classification
3. **Explainability**
   - SHAP for feature contribution visualization
4. **Fairness Audit**
   - Uses `fairlearn` to calculate bias metrics
5. **Ethics Scorecard**
   - Bias, Explainability, and Data Quality combined into a final ethics score
6. **Policy Compliance**
   - Checklist to validate responsible AI practices
7. **Visualization**
   - Plotly gauge to visualize the ethics score

---

## **ðŸ“Š Ethics Score Components**

| Metric | Description |
|---------|-------------|
| **Bias Score** | Based on Demographic Parity & Equalized Odds |
| **Explainability Score** | Based on SHAP visualization availability |
| **Data Diversity Score** | Checks sensitive feature balance |

---

## **ðŸš¦ Ethics Gauge**

The ethics score is visualized using a colored gauge:

- ðŸŸ¢ **85-100:** Excellent Ethics Compliance  
- ðŸŸ¡ **70-85:** Moderate Compliance  
- ðŸ”´ **Below 70:** Needs Improvement  

---

## **ðŸ“œ Policy Compliance Checklist**

| Policy | Status |
|---------|--------|
| Fairness Assessed | âœ… |
| Explainability Verified | âœ… |
| Sensitive Attributes Monitored | âœ… |
| User Consent & Data Validation | âœ… |
| Reproducibility (Colab + Git) | âœ… |

---

## **ðŸ“ˆ Example Output**

- SHAP Summary Plot  
- Fairness Metrics Table  
- Ethics Score Gauge Chart  

---

## **ðŸ“‚ Project Structure**

```
ConscienceAI.ipynb   # Main notebook
README.md             # Project documentation
```

---

## **ðŸ›¡ï¸ License**

This project is licensed under the **MIT License**.

---

## **ðŸ¤ Contributing**

Contributions are welcome! Feel free to fork the repo, submit pull requests, or open issues.

---

## **ðŸ’¬ Contact**

For questions or collaboration:

**Lakshya Verma**  
Lakshya.123607@stu.upes.ac.in
